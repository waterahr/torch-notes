{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will learn how to use multiple GPUs using DataParallel.\n",
    "\n",
    "It’s very easy to use GPUs with PyTorch. You can put the model on a GPU:\n",
    "\n",
    "```\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "```\n",
    "\n",
    "Then, you can copy all your tensors to the GPU:\n",
    "\n",
    "```\n",
    "mytensor = my_tensor.to(device)\n",
    "```\n",
    "\n",
    "Please note that just calling *my_tensor.to(device)* returns a new copy of *my_tensor* on GPU instead of rewriting *my_tensor*. You need to assign it to a new tensor and use that tensor on the GPU.\n",
    "\n",
    "It’s natural to execute your forward, backward propagations on multiple GPUs. However, Pytorch will only use one GPU by default. You can easily run your operations on multiple GPUs by making your model run parallelly using *DataParallel*:\n",
    "\n",
    "```\n",
    "model = nn.DataParallel(model)\n",
    "```\n",
    "\n",
    "That’s the core behind this tutorial. We will explore it in more detail below.\n",
    "\n",
    "# Imports and parameters\n",
    "\n",
    "Import PyTorch modules and define parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Parameters and DataLoaders\n",
    "input_size = 5\n",
    "output_size = 2\n",
    "\n",
    "batch_size = 30\n",
    "data_size = 100\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy DataSet\n",
    "\n",
    "Make a dummy (random) dataset. You just need to implement the getitem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "rand_loader = DataLoader(dataset=RandomDataset(input_size, data_size),\n",
    "                         batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model\n",
    "\n",
    "For the demo, our model just gets an input, performs a linear operation, and gives an output. However, you can use DataParallel on any model (CNN, RNN, Capsule Net etc.)\n",
    "\n",
    "We’ve placed a print statement inside the model to monitor the size of input and output tensors. Please pay attention to what is printed at batch rank 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    # Our model\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.fc(input)\n",
    "        print(\"\\tIn Model: input size\", input.size(),\n",
    "              \"output size\", output.size())\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model and DataParallel\n",
    "\n",
    "This is the core part of the tutorial. First, we need to make a model instance and check if we have multiple GPUs. If we have multiple GPUs, we can wrap our model using *nn.DataParallel*. Then we can put our model on GPUs by *model.to(device)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 3 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Model(\n",
       "    (fc): Linear(in_features=5, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(input_size, output_size)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Model\n",
    "\n",
    "Now we can see the sizes of input and output tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory (malloc at /opt/conda/conda-bld/pytorch_1556653183467/work/c10/cuda/CUDACachingAllocator.cpp:241)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x45 (0x7f05100d9dc5 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x16901 (0x7f05087a4901 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x17347 (0x7f05087a5347 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)\nframe #3: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&) + 0x274 (0x7f0515c86f34 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\nframe #4: at::CUDAType::empty(c10::ArrayRef<long>, c10::TensorOptions const&) const + 0x19b (0x7f05146844cb in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\nframe #5: torch::autograd::VariableType::empty(c10::ArrayRef<long>, c10::TensorOptions const&) const + 0x268 (0x7f05093e5bf8 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libtorch.so.1)\nframe #6: at::native::to(at::Tensor const&, c10::TensorOptions const&, bool, bool) + 0x506 (0x7f0510aa85d6 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\nframe #7: at::TypeDefault::to(at::Tensor const&, c10::TensorOptions const&, bool, bool) const + 0x17 (0x7f0510d277c7 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\nframe #8: torch::autograd::VariableType::to(at::Tensor const&, c10::TensorOptions const&, bool, bool) const + 0x28c (0x7f05092d112c in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libtorch.so.1)\nframe #9: torch::cuda::scatter(at::Tensor const&, c10::ArrayRef<long>, c10::optional<std::vector<long, std::allocator<long> > > const&, long, c10::optional<std::vector<c10::optional<c10::cuda::CUDAStream>, std::allocator<c10::optional<c10::cuda::CUDAStream> > > > const&) + 0x489 (0x7f0509825689 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libtorch.so.1)\nframe #10: <unknown function> + 0x5a7551 (0x7f0536321551 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #11: <unknown function> + 0x12ce4a (0x7f0535ea6e4a in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #12: _PyCFunction_FastCallDict + 0x154 (0x55fa5d3229e4 in /home/anhaoran/anaconda3/bin/python)\nframe #13: <unknown function> + 0x19cdfc (0x55fa5d3afdfc in /home/anhaoran/anaconda3/bin/python)\nframe #14: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #15: <unknown function> + 0x196206 (0x55fa5d3a9206 in /home/anhaoran/anaconda3/bin/python)\nframe #16: <unknown function> + 0x1971cf (0x55fa5d3aa1cf in /home/anhaoran/anaconda3/bin/python)\nframe #17: <unknown function> + 0x19ced5 (0x55fa5d3afed5 in /home/anhaoran/anaconda3/bin/python)\nframe #18: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #19: PyEval_EvalCodeEx + 0x329 (0x55fa5d3aacb9 in /home/anhaoran/anaconda3/bin/python)\nframe #20: <unknown function> + 0x198ac4 (0x55fa5d3abac4 in /home/anhaoran/anaconda3/bin/python)\nframe #21: PyObject_Call + 0x3e (0x55fa5d3227ee in /home/anhaoran/anaconda3/bin/python)\nframe #22: THPFunction_apply(_object*, _object*) + 0x691 (0x7f0536129081 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #23: _PyCFunction_FastCallDict + 0x91 (0x55fa5d322921 in /home/anhaoran/anaconda3/bin/python)\nframe #24: <unknown function> + 0x19cdfc (0x55fa5d3afdfc in /home/anhaoran/anaconda3/bin/python)\nframe #25: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #26: <unknown function> + 0x19662e (0x55fa5d3a962e in /home/anhaoran/anaconda3/bin/python)\nframe #27: _PyFunction_FastCallDict + 0x1bc (0x55fa5d3aa67c in /home/anhaoran/anaconda3/bin/python)\nframe #28: _PyObject_FastCallDict + 0x26f (0x55fa5d322daf in /home/anhaoran/anaconda3/bin/python)\nframe #29: <unknown function> + 0x12afd2 (0x55fa5d33dfd2 in /home/anhaoran/anaconda3/bin/python)\nframe #30: PyIter_Next + 0xe (0x55fa5d3665be in /home/anhaoran/anaconda3/bin/python)\nframe #31: PySequence_Tuple + 0xf9 (0x55fa5d36b379 in /home/anhaoran/anaconda3/bin/python)\nframe #32: _PyEval_EvalFrameDefault + 0x547b (0x55fa5d3d9acb in /home/anhaoran/anaconda3/bin/python)\nframe #33: <unknown function> + 0x19662e (0x55fa5d3a962e in /home/anhaoran/anaconda3/bin/python)\nframe #34: <unknown function> + 0x1971cf (0x55fa5d3aa1cf in /home/anhaoran/anaconda3/bin/python)\nframe #35: <unknown function> + 0x19ced5 (0x55fa5d3afed5 in /home/anhaoran/anaconda3/bin/python)\nframe #36: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #37: <unknown function> + 0x19662e (0x55fa5d3a962e in /home/anhaoran/anaconda3/bin/python)\nframe #38: <unknown function> + 0x1971cf (0x55fa5d3aa1cf in /home/anhaoran/anaconda3/bin/python)\nframe #39: <unknown function> + 0x19ced5 (0x55fa5d3afed5 in /home/anhaoran/anaconda3/bin/python)\nframe #40: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #41: <unknown function> + 0x196206 (0x55fa5d3a9206 in /home/anhaoran/anaconda3/bin/python)\nframe #42: <unknown function> + 0x1971cf (0x55fa5d3aa1cf in /home/anhaoran/anaconda3/bin/python)\nframe #43: <unknown function> + 0x19ced5 (0x55fa5d3afed5 in /home/anhaoran/anaconda3/bin/python)\nframe #44: _PyEval_EvalFrameDefault + 0x10c5 (0x55fa5d3d5715 in /home/anhaoran/anaconda3/bin/python)\nframe #45: <unknown function> + 0x196f8b (0x55fa5d3a9f8b in /home/anhaoran/anaconda3/bin/python)\nframe #46: <unknown function> + 0x19ced5 (0x55fa5d3afed5 in /home/anhaoran/anaconda3/bin/python)\nframe #47: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #48: <unknown function> + 0x196206 (0x55fa5d3a9206 in /home/anhaoran/anaconda3/bin/python)\nframe #49: _PyFunction_FastCallDict + 0x3d7 (0x55fa5d3aa897 in /home/anhaoran/anaconda3/bin/python)\nframe #50: _PyObject_FastCallDict + 0x26f (0x55fa5d322daf in /home/anhaoran/anaconda3/bin/python)\nframe #51: _PyObject_Call_Prepend + 0x63 (0x55fa5d327a73 in /home/anhaoran/anaconda3/bin/python)\nframe #52: PyObject_Call + 0x3e (0x55fa5d3227ee in /home/anhaoran/anaconda3/bin/python)\nframe #53: _PyEval_EvalFrameDefault + 0x1abb (0x55fa5d3d610b in /home/anhaoran/anaconda3/bin/python)\nframe #54: <unknown function> + 0x196206 (0x55fa5d3a9206 in /home/anhaoran/anaconda3/bin/python)\nframe #55: _PyFunction_FastCallDict + 0x1bc (0x55fa5d3aa67c in /home/anhaoran/anaconda3/bin/python)\nframe #56: _PyObject_FastCallDict + 0x26f (0x55fa5d322daf in /home/anhaoran/anaconda3/bin/python)\nframe #57: _PyObject_Call_Prepend + 0x63 (0x55fa5d327a73 in /home/anhaoran/anaconda3/bin/python)\nframe #58: PyObject_Call + 0x3e (0x55fa5d3227ee in /home/anhaoran/anaconda3/bin/python)\nframe #59: <unknown function> + 0x16b897 (0x55fa5d37e897 in /home/anhaoran/anaconda3/bin/python)\nframe #60: _PyObject_FastCallDict + 0x8b (0x55fa5d322bcb in /home/anhaoran/anaconda3/bin/python)\nframe #61: <unknown function> + 0x19cf4e (0x55fa5d3aff4e in /home/anhaoran/anaconda3/bin/python)\nframe #62: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #63: PyEval_EvalCodeEx + 0x329 (0x55fa5d3aacb9 in /home/anhaoran/anaconda3/bin/python)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0f0d83e9ef13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrand_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     print(\"Outside: input size\", input.size(),\n\u001b[1;32m      5\u001b[0m           \"output_size\", output.size())\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                                    \"them on device: {}\".format(self.src_device_obj, t.device))\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, inputs, kwargs, device_ids)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_kwargs\u001b[0;34m(inputs, kwargs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34mr\"\"\"Scatter with support for kwargs dictionary\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(inputs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# None, clearing the cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mscatter_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, target_gpus, chunk_sizes, dim, input)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m# Perform CPU to GPU copies in a background stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mstreams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Synchronize with the copy stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstreams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/comm.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(tensor, devices, chunk_sizes, dim, streams)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory (malloc at /opt/conda/conda-bld/pytorch_1556653183467/work/c10/cuda/CUDACachingAllocator.cpp:241)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x45 (0x7f05100d9dc5 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x16901 (0x7f05087a4901 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x17347 (0x7f05087a5347 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)\nframe #3: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&) + 0x274 (0x7f0515c86f34 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\nframe #4: at::CUDAType::empty(c10::ArrayRef<long>, c10::TensorOptions const&) const + 0x19b (0x7f05146844cb in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\nframe #5: torch::autograd::VariableType::empty(c10::ArrayRef<long>, c10::TensorOptions const&) const + 0x268 (0x7f05093e5bf8 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libtorch.so.1)\nframe #6: at::native::to(at::Tensor const&, c10::TensorOptions const&, bool, bool) + 0x506 (0x7f0510aa85d6 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\nframe #7: at::TypeDefault::to(at::Tensor const&, c10::TensorOptions const&, bool, bool) const + 0x17 (0x7f0510d277c7 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\nframe #8: torch::autograd::VariableType::to(at::Tensor const&, c10::TensorOptions const&, bool, bool) const + 0x28c (0x7f05092d112c in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libtorch.so.1)\nframe #9: torch::cuda::scatter(at::Tensor const&, c10::ArrayRef<long>, c10::optional<std::vector<long, std::allocator<long> > > const&, long, c10::optional<std::vector<c10::optional<c10::cuda::CUDAStream>, std::allocator<c10::optional<c10::cuda::CUDAStream> > > > const&) + 0x489 (0x7f0509825689 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libtorch.so.1)\nframe #10: <unknown function> + 0x5a7551 (0x7f0536321551 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #11: <unknown function> + 0x12ce4a (0x7f0535ea6e4a in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #12: _PyCFunction_FastCallDict + 0x154 (0x55fa5d3229e4 in /home/anhaoran/anaconda3/bin/python)\nframe #13: <unknown function> + 0x19cdfc (0x55fa5d3afdfc in /home/anhaoran/anaconda3/bin/python)\nframe #14: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #15: <unknown function> + 0x196206 (0x55fa5d3a9206 in /home/anhaoran/anaconda3/bin/python)\nframe #16: <unknown function> + 0x1971cf (0x55fa5d3aa1cf in /home/anhaoran/anaconda3/bin/python)\nframe #17: <unknown function> + 0x19ced5 (0x55fa5d3afed5 in /home/anhaoran/anaconda3/bin/python)\nframe #18: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #19: PyEval_EvalCodeEx + 0x329 (0x55fa5d3aacb9 in /home/anhaoran/anaconda3/bin/python)\nframe #20: <unknown function> + 0x198ac4 (0x55fa5d3abac4 in /home/anhaoran/anaconda3/bin/python)\nframe #21: PyObject_Call + 0x3e (0x55fa5d3227ee in /home/anhaoran/anaconda3/bin/python)\nframe #22: THPFunction_apply(_object*, _object*) + 0x691 (0x7f0536129081 in /home/anhaoran/anaconda3/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #23: _PyCFunction_FastCallDict + 0x91 (0x55fa5d322921 in /home/anhaoran/anaconda3/bin/python)\nframe #24: <unknown function> + 0x19cdfc (0x55fa5d3afdfc in /home/anhaoran/anaconda3/bin/python)\nframe #25: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #26: <unknown function> + 0x19662e (0x55fa5d3a962e in /home/anhaoran/anaconda3/bin/python)\nframe #27: _PyFunction_FastCallDict + 0x1bc (0x55fa5d3aa67c in /home/anhaoran/anaconda3/bin/python)\nframe #28: _PyObject_FastCallDict + 0x26f (0x55fa5d322daf in /home/anhaoran/anaconda3/bin/python)\nframe #29: <unknown function> + 0x12afd2 (0x55fa5d33dfd2 in /home/anhaoran/anaconda3/bin/python)\nframe #30: PyIter_Next + 0xe (0x55fa5d3665be in /home/anhaoran/anaconda3/bin/python)\nframe #31: PySequence_Tuple + 0xf9 (0x55fa5d36b379 in /home/anhaoran/anaconda3/bin/python)\nframe #32: _PyEval_EvalFrameDefault + 0x547b (0x55fa5d3d9acb in /home/anhaoran/anaconda3/bin/python)\nframe #33: <unknown function> + 0x19662e (0x55fa5d3a962e in /home/anhaoran/anaconda3/bin/python)\nframe #34: <unknown function> + 0x1971cf (0x55fa5d3aa1cf in /home/anhaoran/anaconda3/bin/python)\nframe #35: <unknown function> + 0x19ced5 (0x55fa5d3afed5 in /home/anhaoran/anaconda3/bin/python)\nframe #36: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #37: <unknown function> + 0x19662e (0x55fa5d3a962e in /home/anhaoran/anaconda3/bin/python)\nframe #38: <unknown function> + 0x1971cf (0x55fa5d3aa1cf in /home/anhaoran/anaconda3/bin/python)\nframe #39: <unknown function> + 0x19ced5 (0x55fa5d3afed5 in /home/anhaoran/anaconda3/bin/python)\nframe #40: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #41: <unknown function> + 0x196206 (0x55fa5d3a9206 in /home/anhaoran/anaconda3/bin/python)\nframe #42: <unknown function> + 0x1971cf (0x55fa5d3aa1cf in /home/anhaoran/anaconda3/bin/python)\nframe #43: <unknown function> + 0x19ced5 (0x55fa5d3afed5 in /home/anhaoran/anaconda3/bin/python)\nframe #44: _PyEval_EvalFrameDefault + 0x10c5 (0x55fa5d3d5715 in /home/anhaoran/anaconda3/bin/python)\nframe #45: <unknown function> + 0x196f8b (0x55fa5d3a9f8b in /home/anhaoran/anaconda3/bin/python)\nframe #46: <unknown function> + 0x19ced5 (0x55fa5d3afed5 in /home/anhaoran/anaconda3/bin/python)\nframe #47: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #48: <unknown function> + 0x196206 (0x55fa5d3a9206 in /home/anhaoran/anaconda3/bin/python)\nframe #49: _PyFunction_FastCallDict + 0x3d7 (0x55fa5d3aa897 in /home/anhaoran/anaconda3/bin/python)\nframe #50: _PyObject_FastCallDict + 0x26f (0x55fa5d322daf in /home/anhaoran/anaconda3/bin/python)\nframe #51: _PyObject_Call_Prepend + 0x63 (0x55fa5d327a73 in /home/anhaoran/anaconda3/bin/python)\nframe #52: PyObject_Call + 0x3e (0x55fa5d3227ee in /home/anhaoran/anaconda3/bin/python)\nframe #53: _PyEval_EvalFrameDefault + 0x1abb (0x55fa5d3d610b in /home/anhaoran/anaconda3/bin/python)\nframe #54: <unknown function> + 0x196206 (0x55fa5d3a9206 in /home/anhaoran/anaconda3/bin/python)\nframe #55: _PyFunction_FastCallDict + 0x1bc (0x55fa5d3aa67c in /home/anhaoran/anaconda3/bin/python)\nframe #56: _PyObject_FastCallDict + 0x26f (0x55fa5d322daf in /home/anhaoran/anaconda3/bin/python)\nframe #57: _PyObject_Call_Prepend + 0x63 (0x55fa5d327a73 in /home/anhaoran/anaconda3/bin/python)\nframe #58: PyObject_Call + 0x3e (0x55fa5d3227ee in /home/anhaoran/anaconda3/bin/python)\nframe #59: <unknown function> + 0x16b897 (0x55fa5d37e897 in /home/anhaoran/anaconda3/bin/python)\nframe #60: _PyObject_FastCallDict + 0x8b (0x55fa5d322bcb in /home/anhaoran/anaconda3/bin/python)\nframe #61: <unknown function> + 0x19cf4e (0x55fa5d3aff4e in /home/anhaoran/anaconda3/bin/python)\nframe #62: _PyEval_EvalFrameDefault + 0x2fa (0x55fa5d3d494a in /home/anhaoran/anaconda3/bin/python)\nframe #63: PyEval_EvalCodeEx + 0x329 (0x55fa5d3aacb9 in /home/anhaoran/anaconda3/bin/python)\n"
     ]
    }
   ],
   "source": [
    "for data in rand_loader:\n",
    "    input = data.to(device)\n",
    "    output = model(input)\n",
    "    print(\"Outside: input size\", input.size(),\n",
    "          \"output_size\", output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "DataParallel splits your data automatically and sends job orders to multiple models on several GPUs. After each model finishes their job, DataParallel collects and merges the results before returning it to you.\n",
    "\n",
    "For more information, please check out https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
