{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks can be constructed using the **torch.nn** package.\n",
    "\n",
    "Now that you had a glimpse of *autograd*, *nn* depends on *autograd* to define models and differentiate them. **An *nn.Module* contains layers, and a method *forward(input)* that returns the output.**\n",
    "\n",
    "For example, look at this network that classifies digit images:\n",
    "![convnet](https://pytorch.org/tutorials/_images/mnist.png)\n",
    "\n",
    "It is a simple feed-forward network. It takes the input, feeds it through several layers one after the other, and then finally gives the output.\n",
    "\n",
    "A typical training procedure for a neural network is as follows:\n",
    "\n",
    "   * Define the neural network that has some learnable parameters (or weights)\n",
    "   * Iterate over a dataset of inputs\n",
    "   * Process input through the network\n",
    "   * Compute the loss (how far is the output from being correct)\n",
    "   * Propagate gradients back into the network’s parameters\n",
    "   * Update the weights of the network, typically using a simple update rule: *weight = weight - learning_rate * gradient*\n",
    "   \n",
    "# Define the network\n",
    "\n",
    "Let's define this network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        # 6*6 from image dimension\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120) \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just have to define the *forward* function, and the *backward* function (where gradients are computed) is automatically defined for you using *autograd*. You can use any of the Tensor operations in the *forward* function.\n",
    "\n",
    "The learnable parameters of a model are returned by *net.parameters()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 3, 3])\n",
      "[Parameter containing:\n",
      "tensor([[[[-0.3303, -0.3248, -0.2974],\n",
      "          [ 0.2254,  0.0792, -0.3230],\n",
      "          [-0.1747, -0.1243, -0.1378]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0455,  0.0913, -0.1205],\n",
      "          [ 0.0057, -0.1815,  0.1762],\n",
      "          [-0.2506,  0.1531, -0.3254]]],\n",
      "\n",
      "\n",
      "        [[[-0.0755,  0.3117, -0.0700],\n",
      "          [ 0.3265,  0.1334, -0.0373],\n",
      "          [-0.1096, -0.2236,  0.0999]]],\n",
      "\n",
      "\n",
      "        [[[-0.2750, -0.0889, -0.1323],\n",
      "          [ 0.0655, -0.1850, -0.0205],\n",
      "          [ 0.2831,  0.2347, -0.0072]]],\n",
      "\n",
      "\n",
      "        [[[-0.3160,  0.0960,  0.1836],\n",
      "          [ 0.0654, -0.3029, -0.2384],\n",
      "          [ 0.2350,  0.0643, -0.2984]]],\n",
      "\n",
      "\n",
      "        [[[-0.3190, -0.2714,  0.1326],\n",
      "          [ 0.1386,  0.1183,  0.2831],\n",
      "          [ 0.1187,  0.2810, -0.1425]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2016,  0.3005,  0.1105, -0.1629,  0.1544, -0.0959],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 2.0907e-02,  1.2704e-01, -7.6882e-02],\n",
      "          [-2.8625e-02,  9.5333e-03, -4.2956e-02],\n",
      "          [-1.0120e-03,  4.0181e-03,  4.1019e-02]],\n",
      "\n",
      "         [[-8.0971e-02, -5.8250e-02, -5.7443e-03],\n",
      "          [ 4.3991e-02, -1.0546e-01, -7.5359e-02],\n",
      "          [ 4.0201e-03,  5.9468e-02, -5.5480e-02]],\n",
      "\n",
      "         [[ 1.5901e-02, -1.0426e-01, -1.3557e-02],\n",
      "          [-9.8238e-02,  4.2264e-02, -9.9777e-02],\n",
      "          [ 6.2706e-02, -1.3266e-02,  6.6799e-03]],\n",
      "\n",
      "         [[-6.3255e-02,  2.1277e-02,  7.6517e-02],\n",
      "          [ 7.8248e-02, -2.4114e-02, -1.2245e-01],\n",
      "          [-9.9526e-03, -3.1389e-02,  1.3131e-01]],\n",
      "\n",
      "         [[-1.2843e-01, -1.9287e-02,  1.0875e-01],\n",
      "          [-4.7891e-02, -4.3015e-02, -1.3187e-01],\n",
      "          [ 2.5913e-02,  1.1880e-01,  1.1569e-01]],\n",
      "\n",
      "         [[ 8.7817e-02,  9.8815e-02, -1.0966e-01],\n",
      "          [-1.1064e-01, -7.2822e-02, -9.0197e-02],\n",
      "          [ 5.6797e-02, -1.2138e-01, -8.8878e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3429e-02, -2.7957e-03,  2.0944e-02],\n",
      "          [-3.0454e-02,  7.6103e-02, -6.6890e-02],\n",
      "          [-3.7001e-02,  2.1109e-02,  4.1664e-02]],\n",
      "\n",
      "         [[ 1.1369e-01, -1.2967e-01,  7.8944e-02],\n",
      "          [ 8.8554e-03, -1.1070e-01,  1.0266e-01],\n",
      "          [-1.1410e-01,  1.0516e-01,  4.5188e-02]],\n",
      "\n",
      "         [[-6.6951e-02,  4.9075e-02,  6.8891e-02],\n",
      "          [ 1.1137e-01, -3.3443e-02,  1.1198e-01],\n",
      "          [ 9.5733e-02, -1.2340e-01,  4.6917e-02]],\n",
      "\n",
      "         [[-1.2584e-01, -3.0852e-02, -4.2675e-02],\n",
      "          [ 1.1501e-01, -8.9686e-02, -1.1758e-01],\n",
      "          [-1.1622e-01, -9.3109e-02, -4.5096e-02]],\n",
      "\n",
      "         [[-7.4413e-02,  9.7938e-02,  5.3194e-02],\n",
      "          [ 1.0826e-01, -4.9268e-02,  6.3920e-02],\n",
      "          [ 8.7306e-02, -6.5506e-02,  5.7217e-03]],\n",
      "\n",
      "         [[ 1.1851e-01,  1.3264e-01, -1.9832e-02],\n",
      "          [-5.8318e-02,  1.0581e-02, -4.2643e-02],\n",
      "          [-4.8858e-02,  4.1724e-02,  4.7447e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.3836e-03, -9.3926e-02, -7.4242e-02],\n",
      "          [-4.6030e-02,  9.4933e-02,  1.0872e-01],\n",
      "          [-8.1978e-02, -2.6354e-03, -1.2641e-01]],\n",
      "\n",
      "         [[-3.5310e-02, -1.0794e-01,  1.2523e-01],\n",
      "          [-1.9488e-02,  2.6939e-02,  9.3293e-02],\n",
      "          [-6.6726e-02, -1.1125e-01, -1.3350e-02]],\n",
      "\n",
      "         [[-1.2160e-01,  3.2502e-02, -1.2896e-01],\n",
      "          [ 1.0622e-01,  9.9290e-02,  1.9350e-02],\n",
      "          [ 5.3611e-02,  1.0897e-02, -6.5185e-02]],\n",
      "\n",
      "         [[ 6.7952e-02, -8.0456e-02,  3.9564e-02],\n",
      "          [ 2.6910e-02, -3.5736e-02, -7.9348e-02],\n",
      "          [ 1.1916e-01,  6.6045e-02, -1.9331e-02]],\n",
      "\n",
      "         [[ 3.0106e-02,  1.7005e-02,  1.8236e-02],\n",
      "          [-5.5302e-02,  3.5463e-03, -1.6312e-02],\n",
      "          [-5.9627e-02,  6.5007e-03,  1.1620e-01]],\n",
      "\n",
      "         [[ 1.3416e-01, -7.9406e-02, -7.3054e-02],\n",
      "          [-2.2179e-02,  6.6777e-02, -2.2189e-02],\n",
      "          [-1.3554e-01, -4.8950e-02, -7.4708e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.6530e-02, -1.1244e-01, -8.4276e-02],\n",
      "          [-7.3503e-02, -3.5424e-02,  1.1965e-01],\n",
      "          [-1.4449e-02, -1.0546e-01,  1.1367e-01]],\n",
      "\n",
      "         [[-1.0850e-01,  1.2473e-02,  1.5183e-02],\n",
      "          [ 8.2458e-02,  5.1836e-03,  1.0567e-01],\n",
      "          [-9.4918e-02,  1.1880e-01, -1.5501e-02]],\n",
      "\n",
      "         [[ 1.0111e-01,  7.0156e-02,  1.1008e-01],\n",
      "          [-6.5338e-02,  5.8115e-07,  1.9614e-03],\n",
      "          [-2.0002e-03, -3.0638e-02,  5.0898e-02]],\n",
      "\n",
      "         [[ 1.8327e-02,  8.2977e-02, -8.8378e-02],\n",
      "          [ 2.9807e-02,  9.4318e-02,  1.3143e-01],\n",
      "          [-9.7781e-02, -3.6067e-02,  1.2118e-01]],\n",
      "\n",
      "         [[-2.2014e-02, -1.3082e-01,  1.0645e-01],\n",
      "          [-1.0324e-01,  7.2628e-02,  7.2018e-02],\n",
      "          [ 1.1229e-01, -4.5700e-02, -5.1887e-02]],\n",
      "\n",
      "         [[ 9.9184e-03, -1.1778e-01, -3.2479e-03],\n",
      "          [ 1.0160e-01,  1.1670e-01,  8.2126e-02],\n",
      "          [ 5.3011e-02, -9.2930e-02, -1.1659e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1767e-02,  9.9469e-02,  1.0945e-01],\n",
      "          [ 1.3350e-01,  2.9902e-02, -5.5528e-02],\n",
      "          [-8.0523e-02,  1.2272e-01,  9.4894e-02]],\n",
      "\n",
      "         [[ 6.0945e-02, -7.0202e-02, -1.2575e-01],\n",
      "          [-6.6231e-03, -1.1380e-01,  6.1411e-02],\n",
      "          [-8.2257e-02, -9.6374e-02, -1.3188e-01]],\n",
      "\n",
      "         [[ 7.2316e-02,  3.1795e-02, -1.1804e-01],\n",
      "          [ 3.6818e-02, -2.2314e-02,  6.2765e-02],\n",
      "          [ 7.2258e-02,  9.2202e-03,  1.3367e-01]],\n",
      "\n",
      "         [[ 1.1003e-01, -9.6564e-02, -1.5379e-02],\n",
      "          [-4.2314e-02,  1.0431e-01,  5.5896e-02],\n",
      "          [ 9.1137e-02, -2.7000e-02,  1.1703e-01]],\n",
      "\n",
      "         [[ 5.8523e-02, -7.8919e-02, -9.0848e-02],\n",
      "          [ 5.2774e-04, -1.0638e-01, -1.2157e-01],\n",
      "          [-3.8636e-02, -1.1487e-01,  7.6651e-02]],\n",
      "\n",
      "         [[-7.3844e-04,  1.2941e-02, -3.1489e-02],\n",
      "          [ 4.0949e-02,  1.2459e-02, -2.9312e-02],\n",
      "          [-1.0436e-01,  1.2157e-01,  3.3482e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7446e-02, -1.1153e-01,  3.7374e-02],\n",
      "          [ 4.9681e-02, -9.8574e-02, -9.6912e-02],\n",
      "          [ 5.1799e-02, -1.2223e-01,  2.6298e-02]],\n",
      "\n",
      "         [[-3.6986e-02, -1.0377e-02,  1.2470e-01],\n",
      "          [ 9.4521e-03,  3.3773e-02,  6.7939e-02],\n",
      "          [-1.0219e-01,  4.9041e-02, -9.3341e-02]],\n",
      "\n",
      "         [[-9.3459e-02, -1.1894e-01, -7.9006e-02],\n",
      "          [-7.0981e-02,  5.1386e-02, -3.2688e-02],\n",
      "          [ 1.2811e-01, -8.5485e-02, -5.0533e-02]],\n",
      "\n",
      "         [[-1.0605e-01,  7.6026e-02,  2.1523e-04],\n",
      "          [ 3.9299e-02,  9.1574e-02,  2.7026e-02],\n",
      "          [ 1.2054e-01, -6.7606e-02, -5.4799e-02]],\n",
      "\n",
      "         [[ 6.9602e-02, -3.7638e-02,  1.8014e-02],\n",
      "          [ 2.3035e-02, -1.5952e-02,  7.2427e-02],\n",
      "          [ 7.3520e-02, -1.7849e-02, -1.2325e-01]],\n",
      "\n",
      "         [[ 4.4105e-02,  1.3014e-01,  8.9854e-02],\n",
      "          [ 4.6899e-02,  9.9946e-02,  3.5186e-02],\n",
      "          [ 1.0969e-02,  6.4408e-02,  5.2374e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.2812e-03,  1.1999e-01, -6.1194e-02],\n",
      "          [ 3.5060e-03, -1.1125e-01,  8.3370e-02],\n",
      "          [ 7.0035e-02,  1.1723e-01, -8.2335e-02]],\n",
      "\n",
      "         [[-3.0322e-02,  2.3551e-02,  7.3674e-02],\n",
      "          [-1.0081e-01,  4.2333e-02, -1.0036e-01],\n",
      "          [-5.0124e-02, -1.6995e-02,  1.0174e-01]],\n",
      "\n",
      "         [[-1.2490e-01, -1.2522e-01, -1.1411e-01],\n",
      "          [ 1.2820e-01,  1.0924e-01,  8.9760e-02],\n",
      "          [-7.6249e-02,  1.3347e-01,  3.8460e-03]],\n",
      "\n",
      "         [[ 1.1007e-01,  1.2625e-01,  1.0455e-03],\n",
      "          [ 1.0053e-01,  8.8256e-02,  1.3093e-01],\n",
      "          [-8.6602e-02,  1.5461e-02,  5.6471e-02]],\n",
      "\n",
      "         [[-6.0744e-02, -1.2947e-02, -4.3033e-02],\n",
      "          [-5.3585e-02, -3.1389e-02,  2.1682e-02],\n",
      "          [ 5.3913e-02, -1.1540e-01, -3.8497e-02]],\n",
      "\n",
      "         [[ 4.5278e-02, -1.3523e-01,  8.7068e-02],\n",
      "          [-1.1388e-01,  4.4173e-02, -9.9969e-02],\n",
      "          [ 5.0802e-02, -2.6719e-02, -1.3499e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.5085e-02,  7.7995e-02,  2.6444e-02],\n",
      "          [-1.3487e-02,  1.2516e-01,  1.0394e-01],\n",
      "          [-5.9709e-02,  3.4738e-02, -1.1130e-01]],\n",
      "\n",
      "         [[-1.2392e-01,  1.2372e-01, -9.6790e-02],\n",
      "          [-8.5668e-02, -2.7930e-02, -6.0333e-02],\n",
      "          [-9.9579e-02, -7.1871e-02,  4.5757e-02]],\n",
      "\n",
      "         [[ 3.8968e-02, -9.0137e-05,  4.5449e-02],\n",
      "          [-4.0510e-02,  4.8657e-02, -7.6832e-02],\n",
      "          [ 6.4394e-02,  9.2211e-02,  5.3414e-02]],\n",
      "\n",
      "         [[ 5.1344e-02, -1.0282e-01, -1.1876e-01],\n",
      "          [-9.1052e-02, -2.6454e-02,  9.8636e-02],\n",
      "          [-2.1636e-02,  1.1810e-01, -1.2495e-01]],\n",
      "\n",
      "         [[ 6.9261e-02,  6.0938e-02, -2.1064e-02],\n",
      "          [-9.7097e-02,  1.2718e-01,  7.9729e-03],\n",
      "          [ 1.5626e-02,  1.2175e-01, -5.0059e-02]],\n",
      "\n",
      "         [[-3.3323e-02,  1.2271e-01, -1.2716e-01],\n",
      "          [ 3.5702e-02, -5.1601e-02,  1.2131e-01],\n",
      "          [ 4.0744e-02, -5.0707e-02,  1.0666e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9056e-02,  4.5031e-02, -1.3430e-01],\n",
      "          [-6.3772e-02,  7.8533e-03,  3.0799e-02],\n",
      "          [ 6.6205e-03, -1.0911e-01, -9.7324e-02]],\n",
      "\n",
      "         [[ 1.1031e-01, -6.3537e-02, -9.8513e-02],\n",
      "          [ 9.7481e-02,  3.0700e-02,  4.0171e-02],\n",
      "          [-8.2764e-02,  6.4561e-02, -9.0117e-02]],\n",
      "\n",
      "         [[-1.0199e-01, -5.2193e-02, -1.2563e-01],\n",
      "          [ 1.1917e-01, -5.6377e-02, -7.6078e-02],\n",
      "          [ 5.1934e-02, -8.4189e-02,  1.9930e-03]],\n",
      "\n",
      "         [[ 9.0228e-03,  3.5279e-02, -1.8806e-02],\n",
      "          [-3.1391e-02, -5.7972e-02,  1.2684e-02],\n",
      "          [-1.3964e-02, -6.7286e-02, -1.2986e-01]],\n",
      "\n",
      "         [[-1.0889e-01, -2.1773e-02, -1.0486e-01],\n",
      "          [ 1.3376e-01, -8.0661e-02, -8.2878e-02],\n",
      "          [ 8.2464e-02,  1.0742e-01, -3.7778e-02]],\n",
      "\n",
      "         [[ 1.2393e-01,  4.4909e-03, -8.6405e-02],\n",
      "          [ 1.0331e-01,  1.2046e-01, -1.4743e-02],\n",
      "          [ 1.3327e-01, -1.8029e-02,  1.3437e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2610e-01,  1.2111e-01,  4.4115e-02],\n",
      "          [-9.8117e-02, -1.3091e-01,  9.6552e-02],\n",
      "          [ 8.9039e-02,  1.0231e-01,  1.2626e-02]],\n",
      "\n",
      "         [[ 6.4398e-02,  1.6004e-02, -6.8116e-02],\n",
      "          [ 5.7237e-03, -9.2898e-02, -8.7898e-02],\n",
      "          [-7.9583e-03, -6.6397e-02, -2.6520e-02]],\n",
      "\n",
      "         [[-5.6152e-02, -1.8153e-02, -8.8925e-02],\n",
      "          [ 3.5860e-02, -9.3099e-02, -2.5808e-02],\n",
      "          [-4.1223e-02, -1.2669e-01, -1.0814e-01]],\n",
      "\n",
      "         [[-1.3235e-01,  1.1066e-01,  1.0705e-01],\n",
      "          [ 9.7850e-03, -4.9224e-02,  2.6405e-02],\n",
      "          [ 3.5549e-02, -7.6183e-02,  5.6039e-02]],\n",
      "\n",
      "         [[-1.2204e-01,  1.3450e-01, -1.3626e-02],\n",
      "          [ 3.7659e-02,  3.1210e-02, -4.0300e-02],\n",
      "          [ 1.0493e-01,  5.1679e-02,  7.5317e-02]],\n",
      "\n",
      "         [[-1.3486e-01, -1.2380e-01, -3.2159e-02],\n",
      "          [-5.9748e-02, -2.6439e-03,  1.8119e-03],\n",
      "          [-8.5046e-02, -4.5375e-02,  4.9504e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2174e-01, -5.3732e-02,  6.6692e-02],\n",
      "          [-5.5783e-03, -1.1298e-01, -7.3204e-02],\n",
      "          [ 1.5686e-03,  7.4089e-02,  7.2027e-02]],\n",
      "\n",
      "         [[ 7.6849e-02, -1.2971e-01,  1.2615e-01],\n",
      "          [-2.2438e-02,  4.7807e-02,  1.2082e-01],\n",
      "          [-9.0290e-03,  6.4600e-02,  9.2396e-02]],\n",
      "\n",
      "         [[ 4.6990e-02, -5.8779e-02, -6.0021e-02],\n",
      "          [-4.5142e-02, -8.8880e-03, -4.6971e-02],\n",
      "          [-9.0420e-02, -6.6816e-02, -1.0974e-01]],\n",
      "\n",
      "         [[ 4.0506e-02, -8.7034e-03,  4.0737e-02],\n",
      "          [ 6.4313e-02, -9.1966e-02,  7.1891e-02],\n",
      "          [-1.3192e-01,  5.4018e-02,  9.3789e-02]],\n",
      "\n",
      "         [[ 4.5290e-03,  3.7150e-02, -5.2628e-02],\n",
      "          [ 2.4452e-02,  5.2724e-02,  7.8116e-02],\n",
      "          [ 1.2391e-01, -9.3485e-02, -1.3443e-01]],\n",
      "\n",
      "         [[ 1.0673e-01, -9.0788e-02, -1.0484e-02],\n",
      "          [-1.1384e-01, -7.8766e-02, -3.4549e-02],\n",
      "          [-8.0286e-03,  8.2381e-02,  6.3246e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1199e-02,  1.2885e-01,  8.5348e-02],\n",
      "          [-4.0207e-02,  8.3397e-02,  1.2619e-01],\n",
      "          [ 3.8391e-03,  8.6172e-02,  3.0954e-02]],\n",
      "\n",
      "         [[-5.1757e-02,  1.7274e-02, -4.6295e-02],\n",
      "          [ 3.9641e-02, -1.7996e-02, -8.3241e-02],\n",
      "          [ 1.0817e-01, -6.1669e-02, -1.4128e-02]],\n",
      "\n",
      "         [[ 1.0974e-01, -4.6572e-02, -9.8995e-02],\n",
      "          [ 4.7518e-02,  4.1156e-02,  4.4041e-02],\n",
      "          [-1.1751e-01, -7.0996e-02, -1.0154e-01]],\n",
      "\n",
      "         [[-2.1243e-02,  6.7247e-03,  1.2387e-01],\n",
      "          [ 1.2546e-01,  3.1085e-02, -9.2117e-02],\n",
      "          [-8.5071e-02,  9.4371e-02,  3.1663e-02]],\n",
      "\n",
      "         [[-3.6964e-02, -5.6407e-02,  1.3256e-01],\n",
      "          [-4.4451e-02,  4.6240e-02,  6.4649e-02],\n",
      "          [-1.2070e-01, -1.3218e-01, -1.0715e-02]],\n",
      "\n",
      "         [[ 4.4472e-02, -8.5546e-02,  6.6262e-02],\n",
      "          [-8.9768e-02, -3.1905e-02, -4.2192e-02],\n",
      "          [ 6.6815e-03, -1.0821e-01,  2.7442e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1911e-02, -5.9517e-02,  5.6620e-02],\n",
      "          [-9.5756e-02, -3.2978e-03,  1.8457e-02],\n",
      "          [-8.7572e-02,  1.3109e-01,  6.1562e-02]],\n",
      "\n",
      "         [[ 1.0017e-01,  7.4420e-02, -4.1413e-02],\n",
      "          [-1.3502e-01, -3.4116e-02, -1.6256e-02],\n",
      "          [ 1.1220e-02,  1.2429e-01, -8.8031e-02]],\n",
      "\n",
      "         [[-1.2814e-01,  6.4583e-02, -1.0754e-01],\n",
      "          [-2.4698e-02,  1.1880e-01, -9.2014e-02],\n",
      "          [-1.2722e-01,  8.1447e-02, -1.1713e-01]],\n",
      "\n",
      "         [[ 8.5509e-02, -2.9287e-02,  3.1186e-02],\n",
      "          [-1.2572e-01, -2.0791e-02,  1.2776e-01],\n",
      "          [-1.2150e-01,  3.6472e-02,  1.2711e-01]],\n",
      "\n",
      "         [[-6.0899e-02,  1.2264e-02, -8.8053e-03],\n",
      "          [ 4.3082e-02, -7.6767e-02, -8.6564e-02],\n",
      "          [ 5.9838e-02,  4.2572e-02, -4.1853e-02]],\n",
      "\n",
      "         [[ 6.9267e-02,  3.2222e-02,  5.7643e-02],\n",
      "          [-1.0869e-01, -1.2234e-01, -1.9343e-02],\n",
      "          [ 8.0210e-02,  1.9649e-02, -5.8364e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1405e-02,  1.2021e-01, -1.2549e-01],\n",
      "          [ 1.1664e-01,  4.8168e-02,  1.3189e-01],\n",
      "          [ 1.4751e-02,  5.0828e-02,  3.8832e-02]],\n",
      "\n",
      "         [[-1.2632e-02,  3.5887e-02, -1.2791e-01],\n",
      "          [-3.2769e-02,  1.2041e-01, -6.7186e-02],\n",
      "          [ 1.1726e-01, -6.4635e-02, -2.5849e-02]],\n",
      "\n",
      "         [[-6.1061e-02,  1.0575e-01,  4.7688e-02],\n",
      "          [ 1.1734e-01, -4.3501e-02, -4.8446e-02],\n",
      "          [-3.7907e-02,  8.0966e-02,  7.5761e-02]],\n",
      "\n",
      "         [[-7.4261e-02,  1.1704e-01,  9.9309e-02],\n",
      "          [ 4.9307e-03,  7.8948e-02, -1.0511e-01],\n",
      "          [-1.0907e-01, -1.1972e-02, -3.9766e-03]],\n",
      "\n",
      "         [[ 1.1393e-01, -7.2718e-02, -4.6309e-02],\n",
      "          [ 1.7773e-03, -7.3949e-02, -9.6253e-02],\n",
      "          [-8.3321e-02, -4.7524e-02, -1.2626e-01]],\n",
      "\n",
      "         [[ 7.1010e-02,  9.9804e-02, -3.1112e-02],\n",
      "          [-3.2822e-02,  1.1126e-01, -1.1252e-02],\n",
      "          [ 2.6262e-03,  1.1765e-01, -5.0305e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4605e-02, -1.1598e-01,  1.2549e-01],\n",
      "          [-6.4390e-02,  4.1442e-02, -7.7150e-03],\n",
      "          [-2.1622e-04, -1.0604e-01,  3.3582e-02]],\n",
      "\n",
      "         [[-1.2991e-01, -1.2416e-01, -2.3065e-02],\n",
      "          [-8.7907e-03,  8.9949e-02,  2.8165e-02],\n",
      "          [-9.7602e-02, -6.0883e-02, -4.7505e-02]],\n",
      "\n",
      "         [[-6.9943e-02,  9.4351e-03,  1.2902e-01],\n",
      "          [-1.0645e-01, -3.6175e-02,  1.1262e-01],\n",
      "          [-8.8802e-04, -8.0539e-02, -9.8854e-02]],\n",
      "\n",
      "         [[-1.3391e-01, -1.0043e-01,  9.9629e-02],\n",
      "          [ 7.7007e-02,  5.9488e-02,  1.6646e-02],\n",
      "          [-1.2996e-01, -1.2522e-01, -1.0920e-01]],\n",
      "\n",
      "         [[ 3.0729e-03,  4.8626e-02, -9.1884e-02],\n",
      "          [-4.0336e-02,  5.8066e-02, -3.2159e-03],\n",
      "          [-9.4022e-02, -1.0724e-01, -7.0593e-02]],\n",
      "\n",
      "         [[ 4.5883e-02,  6.7735e-02, -1.2570e-01],\n",
      "          [-2.6509e-02, -1.4199e-02, -6.2522e-02],\n",
      "          [ 9.2802e-02,  1.2934e-01,  7.4509e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0533e-01,  3.1075e-02,  1.1244e-01],\n",
      "          [ 2.9015e-02, -1.6950e-02, -4.5608e-02],\n",
      "          [-6.7467e-02,  8.1739e-03,  9.3089e-02]],\n",
      "\n",
      "         [[-5.8155e-02,  5.6000e-02, -1.0312e-01],\n",
      "          [ 7.4431e-02, -6.2218e-02,  2.8842e-02],\n",
      "          [-1.0528e-01,  8.3321e-02, -1.2999e-01]],\n",
      "\n",
      "         [[ 1.1079e-01, -6.2442e-02,  1.1127e-01],\n",
      "          [ 9.0050e-02,  4.4448e-02,  5.0283e-02],\n",
      "          [-1.1125e-01,  5.9871e-03, -9.9358e-02]],\n",
      "\n",
      "         [[ 3.8656e-02,  3.0307e-02, -1.6063e-02],\n",
      "          [-1.1890e-02, -7.7304e-02, -9.5210e-02],\n",
      "          [ 5.1238e-02, -3.8081e-02,  1.2136e-01]],\n",
      "\n",
      "         [[ 9.9274e-02,  1.3474e-01,  6.5224e-02],\n",
      "          [-3.3397e-02,  8.9350e-02,  7.2377e-02],\n",
      "          [-5.0687e-02,  1.1714e-01,  1.1321e-01]],\n",
      "\n",
      "         [[-5.9173e-02, -1.2035e-01, -5.4870e-03],\n",
      "          [-3.8747e-02, -4.5315e-03,  1.3581e-01],\n",
      "          [-1.0421e-01,  8.4686e-02,  4.2989e-02]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0863, -0.0935, -0.0450,  0.0878,  0.0580,  0.0591,  0.0676, -0.0960,\n",
      "        -0.0348,  0.0242, -0.0872, -0.0674,  0.0085,  0.1212,  0.0797,  0.0998],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0227, -0.0162, -0.0133,  ...,  0.0202, -0.0096, -0.0124],\n",
      "        [ 0.0226,  0.0137, -0.0168,  ..., -0.0197, -0.0261, -0.0201],\n",
      "        [-0.0124, -0.0291,  0.0312,  ..., -0.0248, -0.0210, -0.0270],\n",
      "        ...,\n",
      "        [-0.0203, -0.0398, -0.0285,  ...,  0.0091, -0.0404,  0.0237],\n",
      "        [ 0.0132, -0.0194,  0.0204,  ...,  0.0232, -0.0220, -0.0299],\n",
      "        [ 0.0014, -0.0150,  0.0216,  ..., -0.0310, -0.0189,  0.0182]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0152, -0.0282,  0.0280,  0.0092,  0.0347,  0.0103,  0.0414,  0.0068,\n",
      "         0.0072,  0.0164,  0.0363,  0.0367, -0.0129,  0.0024,  0.0191,  0.0070,\n",
      "         0.0206, -0.0101,  0.0198,  0.0338, -0.0250,  0.0110, -0.0202, -0.0341,\n",
      "        -0.0314,  0.0225,  0.0362, -0.0087,  0.0122, -0.0040, -0.0271,  0.0348,\n",
      "         0.0272,  0.0236, -0.0113, -0.0006, -0.0256,  0.0300, -0.0022, -0.0142,\n",
      "         0.0029, -0.0206,  0.0083, -0.0096, -0.0129,  0.0155,  0.0208,  0.0085,\n",
      "         0.0066,  0.0028,  0.0282, -0.0061,  0.0352,  0.0393,  0.0329, -0.0175,\n",
      "         0.0404, -0.0411, -0.0094,  0.0182, -0.0096,  0.0163,  0.0171,  0.0027,\n",
      "        -0.0034, -0.0099, -0.0221, -0.0212,  0.0149, -0.0186, -0.0257, -0.0348,\n",
      "         0.0316,  0.0159,  0.0193,  0.0155, -0.0065, -0.0335,  0.0092,  0.0369,\n",
      "         0.0250, -0.0029,  0.0122, -0.0093,  0.0238, -0.0370, -0.0081,  0.0086,\n",
      "        -0.0384, -0.0288, -0.0231, -0.0382,  0.0130, -0.0388, -0.0350,  0.0202,\n",
      "         0.0362,  0.0077, -0.0342,  0.0212, -0.0203,  0.0220,  0.0108,  0.0138,\n",
      "         0.0010,  0.0208, -0.0168,  0.0188,  0.0323,  0.0223,  0.0235, -0.0140,\n",
      "        -0.0183,  0.0102, -0.0130,  0.0187,  0.0389,  0.0057, -0.0375,  0.0257],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0913, -0.0122,  0.0359,  ..., -0.0353,  0.0279, -0.0022],\n",
      "        [-0.0762,  0.0004,  0.0040,  ...,  0.0834,  0.0838,  0.0853],\n",
      "        [ 0.0062, -0.0258,  0.0815,  ..., -0.0175, -0.0194,  0.0835],\n",
      "        ...,\n",
      "        [ 0.0720,  0.0648, -0.0007,  ..., -0.0533, -0.0233,  0.0265],\n",
      "        [ 0.0430, -0.0714, -0.0671,  ...,  0.0026,  0.0788,  0.0326],\n",
      "        [ 0.0617, -0.0108,  0.0570,  ..., -0.0670,  0.0260,  0.0746]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0001, -0.0350,  0.0634,  0.0500, -0.0586,  0.0804,  0.0503,  0.0477,\n",
      "        -0.0848, -0.0383,  0.0420,  0.0609,  0.0791, -0.0375,  0.0247, -0.0652,\n",
      "         0.0773, -0.0833,  0.0400, -0.0435, -0.0673, -0.0019,  0.0112, -0.0599,\n",
      "         0.0628, -0.0550, -0.0787, -0.0173, -0.0073, -0.0177,  0.0259,  0.0596,\n",
      "        -0.0803,  0.0720, -0.0772,  0.0449,  0.0427, -0.0442,  0.0073, -0.0767,\n",
      "        -0.0642, -0.0661, -0.0076,  0.0911, -0.0705, -0.0540, -0.0143,  0.0458,\n",
      "        -0.0344,  0.0229,  0.0107, -0.0088, -0.0296, -0.0442, -0.0517, -0.0539,\n",
      "        -0.0684,  0.0132,  0.0395, -0.0507,  0.0388, -0.0378, -0.0890,  0.0710,\n",
      "         0.0182,  0.0100, -0.0790,  0.0174, -0.0283, -0.0590, -0.0348,  0.0101,\n",
      "        -0.0782, -0.0833, -0.0166, -0.0473,  0.0879,  0.0740,  0.0610, -0.0087,\n",
      "        -0.0833,  0.0147,  0.0557,  0.0391], requires_grad=True), Parameter containing:\n",
      "tensor([[-3.4434e-03, -6.2545e-02,  4.8985e-02, -3.9418e-03, -1.5341e-02,\n",
      "          4.3675e-05,  5.0943e-03,  3.2931e-02, -6.8701e-02,  3.7807e-02,\n",
      "          4.0344e-02,  1.0800e-01,  1.0347e-01, -3.5774e-02,  2.8364e-02,\n",
      "         -3.2751e-02, -8.2524e-02,  4.8028e-02,  2.0551e-02,  1.4090e-02,\n",
      "         -3.6931e-02,  8.0634e-02, -9.7609e-03,  4.8797e-02,  4.6734e-02,\n",
      "         -6.1678e-02, -3.4122e-02, -2.5553e-02, -8.4840e-02, -1.0112e-01,\n",
      "         -7.5116e-02, -5.9843e-02, -2.9283e-03,  5.0129e-02,  6.1383e-02,\n",
      "          2.9834e-02,  1.0254e-01,  3.0510e-02,  7.9084e-02,  2.1241e-03,\n",
      "          6.7919e-02, -4.2804e-02,  2.4567e-02, -7.2816e-03, -3.0225e-02,\n",
      "          7.9189e-02,  9.0638e-02,  8.2699e-02,  9.5218e-02,  7.7483e-02,\n",
      "         -8.0425e-02,  7.7675e-02, -9.5081e-02,  9.1719e-02, -1.0861e-01,\n",
      "         -1.0001e-01,  2.0638e-02, -1.5463e-02, -7.1304e-02,  7.2992e-02,\n",
      "          6.0265e-02, -9.6097e-02, -1.0327e-01,  6.1601e-02,  9.1307e-02,\n",
      "         -1.0066e-01, -4.1084e-02, -6.2930e-02,  8.2509e-02,  9.6149e-02,\n",
      "         -9.0962e-02, -7.4046e-02, -2.6129e-02, -1.4967e-02,  3.2503e-02,\n",
      "          6.9989e-02,  6.7445e-03, -6.6936e-02, -7.6293e-02, -8.3142e-02,\n",
      "         -4.8058e-02,  2.4223e-02,  5.2704e-02,  1.1783e-02],\n",
      "        [ 3.7278e-02, -9.9506e-02,  6.1797e-02, -6.1085e-02, -3.0921e-03,\n",
      "         -2.3368e-02, -9.2480e-02, -2.8084e-02,  2.3957e-02,  2.2863e-03,\n",
      "         -2.7027e-02,  9.6730e-02, -7.4222e-02, -4.8345e-02, -9.3826e-02,\n",
      "         -1.7515e-02,  9.9832e-02,  3.9737e-02,  4.8272e-02,  7.1247e-03,\n",
      "         -3.7774e-03, -4.7307e-03, -7.7517e-02,  7.5905e-02, -7.9679e-03,\n",
      "         -9.5001e-02,  1.0807e-01, -8.4175e-02,  3.8128e-02, -9.6162e-02,\n",
      "          2.0050e-03,  4.2110e-02,  1.0164e-01, -3.3754e-02, -1.9670e-02,\n",
      "          3.6527e-02, -1.8361e-02,  1.2497e-02, -1.6193e-02,  1.0386e-01,\n",
      "         -1.0133e-01, -2.8673e-02, -1.2097e-02,  7.2452e-02,  5.2668e-02,\n",
      "          7.9502e-02,  1.5291e-02,  1.0351e-01,  7.1989e-02, -1.7689e-02,\n",
      "          3.4669e-02,  4.2827e-02,  1.8479e-02, -8.3753e-02, -2.1263e-02,\n",
      "          6.8544e-02,  5.9242e-02, -5.4339e-02, -6.0437e-02,  9.0266e-02,\n",
      "         -4.0604e-02,  8.6055e-02, -4.6919e-02,  4.7656e-02, -2.7342e-02,\n",
      "          4.7330e-02,  4.0375e-02, -8.7113e-02, -9.1656e-02, -9.1070e-02,\n",
      "          9.3274e-02, -2.0947e-02,  4.4249e-02, -5.2871e-02,  8.6225e-02,\n",
      "         -8.3394e-02,  1.1662e-02, -7.3911e-03,  8.9208e-03, -9.8808e-02,\n",
      "          4.2985e-02, -5.1041e-02, -1.3734e-02, -8.0280e-03],\n",
      "        [ 7.3032e-02, -2.7859e-02, -7.9329e-02,  8.8993e-02, -8.7972e-02,\n",
      "          5.2509e-02, -7.1825e-03, -7.1389e-02, -6.2364e-02,  8.9879e-02,\n",
      "          7.7714e-02, -2.1693e-04,  5.7434e-02, -9.5233e-02,  1.0076e-01,\n",
      "         -6.2804e-02, -9.9105e-02,  9.8459e-02,  8.1643e-02, -2.5915e-02,\n",
      "         -9.5884e-03,  1.2373e-02, -7.4154e-02, -6.0229e-02, -5.3796e-02,\n",
      "          7.5710e-02,  8.3392e-02, -6.0318e-03, -6.3243e-02, -4.9211e-02,\n",
      "         -5.8846e-02, -1.0650e-01, -1.7499e-04, -4.8103e-02,  4.3103e-02,\n",
      "         -4.0830e-02, -4.6152e-02,  4.7477e-02, -6.1151e-02,  3.9531e-02,\n",
      "          5.3723e-02, -3.0219e-03,  6.1296e-02,  3.9778e-02,  5.0866e-02,\n",
      "         -4.9024e-02, -1.7584e-02,  3.9504e-02, -6.5480e-02, -1.7773e-02,\n",
      "          2.6709e-02,  2.7697e-02, -6.6165e-02, -4.7475e-02, -6.1203e-02,\n",
      "         -9.9387e-02, -7.4682e-02,  1.0702e-01,  4.7011e-02,  3.8083e-02,\n",
      "         -6.7155e-02,  2.2071e-02, -4.7129e-02,  1.4502e-02,  1.1770e-03,\n",
      "          1.0799e-01,  2.1164e-02,  5.1656e-02,  7.7895e-02, -5.4594e-02,\n",
      "          6.2728e-02, -3.1689e-02, -2.5664e-02, -1.0226e-01,  7.9105e-02,\n",
      "         -8.9939e-02, -3.9357e-02,  2.2727e-02, -8.0013e-02,  1.0173e-02,\n",
      "         -3.3470e-02,  9.9768e-03,  2.5995e-02, -3.5440e-02],\n",
      "        [-6.1367e-02,  5.2721e-02, -1.2486e-02, -5.9861e-02,  6.2893e-02,\n",
      "          4.7222e-02, -3.6358e-02, -2.8063e-02,  9.1405e-02,  5.4792e-03,\n",
      "          9.2616e-02,  8.7147e-02, -1.3264e-02,  5.4755e-02, -7.6342e-02,\n",
      "         -5.5483e-02,  9.8394e-02, -8.2577e-02,  6.8601e-02, -2.6401e-02,\n",
      "          1.6766e-02,  8.4392e-02, -8.1448e-02, -8.5524e-03,  9.9466e-02,\n",
      "          8.6694e-02, -1.4066e-02,  9.5300e-02,  3.5639e-02, -8.0564e-02,\n",
      "          4.5132e-02, -1.8587e-03, -7.7736e-02, -1.5198e-02,  9.6273e-03,\n",
      "         -6.1916e-02, -9.3454e-02,  4.1083e-02, -5.5016e-02,  5.7371e-02,\n",
      "         -3.8770e-02,  2.0459e-02,  5.4341e-02, -1.0318e-01, -5.9406e-02,\n",
      "         -8.8557e-02,  1.4738e-02, -2.1891e-02,  2.8129e-02,  2.9650e-02,\n",
      "          2.2732e-02,  1.4111e-02,  5.2928e-03,  1.0437e-01,  1.0430e-01,\n",
      "          4.6682e-02, -1.8397e-02,  5.3162e-02,  3.1730e-02,  4.1383e-02,\n",
      "         -7.6084e-02, -1.0108e-01, -6.1749e-03,  8.1146e-02,  1.0536e-01,\n",
      "          8.6561e-02,  5.1279e-02,  8.4339e-02,  9.0847e-02,  3.0228e-02,\n",
      "          1.0675e-02,  4.3141e-03,  7.2249e-02,  6.9474e-02,  5.2780e-02,\n",
      "          1.0293e-01,  5.7904e-03,  8.3522e-02,  8.6212e-02, -6.9221e-02,\n",
      "         -4.6120e-02, -1.8851e-02, -5.9460e-02, -1.2183e-02],\n",
      "        [-9.8644e-02, -1.8480e-02,  2.8815e-02,  8.6880e-02,  1.0718e-01,\n",
      "         -1.9761e-02,  6.4623e-02, -8.6656e-02,  1.0803e-01,  6.2277e-02,\n",
      "         -4.5938e-02,  2.3831e-02,  6.2700e-02,  2.7540e-02, -9.6294e-02,\n",
      "         -7.5470e-02,  7.7103e-02,  1.5623e-02,  7.4892e-02, -9.7822e-02,\n",
      "          4.0053e-02,  2.7364e-02,  7.6501e-03, -4.3764e-02, -5.3293e-02,\n",
      "         -4.3545e-02, -4.7795e-03,  3.9661e-02,  6.8390e-02, -5.0860e-02,\n",
      "         -2.1350e-02, -9.9387e-02,  7.7435e-02, -5.6845e-02,  4.5795e-02,\n",
      "         -9.1987e-02,  5.6636e-02, -5.7481e-02,  8.8451e-02, -3.8816e-02,\n",
      "         -5.6444e-02, -6.3920e-02, -9.0979e-02, -1.0485e-01,  2.5046e-02,\n",
      "         -5.8318e-02, -1.0673e-01,  9.2887e-02, -8.2032e-02, -1.0001e-01,\n",
      "          7.8885e-02, -8.9129e-02,  1.1913e-02, -8.2793e-02,  7.2119e-02,\n",
      "         -4.7952e-02, -4.5074e-02,  4.6535e-02,  3.3174e-02,  3.1553e-02,\n",
      "         -3.8473e-02,  6.0797e-02,  8.6053e-02,  6.4935e-02,  7.2406e-02,\n",
      "         -9.7147e-02,  7.5919e-02, -7.3388e-02, -8.1660e-02, -3.7019e-02,\n",
      "         -5.1021e-02,  1.2933e-02,  9.0218e-02,  7.7664e-02, -1.7286e-02,\n",
      "          9.4654e-02,  1.0559e-01, -1.0622e-01, -7.1768e-02, -4.2450e-02,\n",
      "          2.6984e-02,  9.3609e-02,  6.2006e-02, -4.3711e-02],\n",
      "        [-4.7081e-02,  4.8692e-02,  1.3986e-02, -8.8194e-02,  5.3263e-02,\n",
      "         -2.0249e-02, -1.2274e-02, -4.2372e-02,  4.2133e-02,  9.7559e-02,\n",
      "          7.3034e-02,  1.0518e-01,  3.0450e-02,  3.1689e-02,  1.0174e-01,\n",
      "         -9.2918e-02, -9.0514e-02,  3.0659e-03,  5.4957e-02,  9.1943e-02,\n",
      "         -2.2675e-02,  3.7721e-02, -1.4122e-03, -4.3277e-02,  7.2461e-02,\n",
      "         -4.3861e-03,  1.2676e-02, -6.0193e-02,  6.9952e-02,  9.3096e-02,\n",
      "          7.4922e-02, -8.3567e-02,  1.8163e-02,  4.9900e-02, -8.1222e-02,\n",
      "          7.1702e-02, -5.8290e-02, -2.2983e-02, -1.0627e-02,  7.8344e-02,\n",
      "          2.8096e-02, -9.5488e-02, -4.4518e-02, -1.3995e-02, -6.9617e-02,\n",
      "          7.7356e-02,  8.8619e-02,  5.6910e-02, -5.3038e-02, -7.8331e-03,\n",
      "          2.8329e-02, -1.7397e-03, -5.6094e-02, -2.8349e-02,  9.0374e-02,\n",
      "          4.0483e-02,  2.4257e-02, -2.1075e-02,  1.0717e-01,  2.0092e-02,\n",
      "          6.6852e-02,  7.4527e-02, -7.3357e-02,  4.3082e-02,  1.7637e-02,\n",
      "          3.7402e-03,  8.2602e-02, -3.2721e-02,  1.1513e-02, -4.6019e-02,\n",
      "          6.6726e-02, -4.0648e-02, -8.3736e-02,  5.2153e-02, -1.0379e-01,\n",
      "         -9.1390e-03, -4.3749e-02,  7.2575e-02, -1.7978e-02,  6.1293e-02,\n",
      "          7.0478e-02, -4.7294e-02, -1.3659e-02, -8.6037e-02],\n",
      "        [-9.7964e-02, -2.9226e-02,  4.9778e-02, -6.0275e-02, -7.2077e-02,\n",
      "         -6.0377e-02,  1.7992e-02, -4.2510e-02,  1.7009e-02, -9.1589e-02,\n",
      "          2.8128e-02, -1.0128e-01,  7.9531e-02,  6.4158e-02, -2.0559e-02,\n",
      "          5.6742e-02, -1.6366e-02,  8.4045e-02,  8.6445e-02, -9.4376e-02,\n",
      "          7.0580e-02, -9.9121e-02,  8.1427e-02,  7.4799e-02, -1.7867e-02,\n",
      "          7.5585e-02,  6.1166e-02,  4.1954e-02,  1.0580e-01, -1.0012e-01,\n",
      "          1.5071e-02, -8.7848e-02,  8.9225e-02, -4.6050e-02, -2.4112e-02,\n",
      "         -2.9572e-02,  6.0694e-02, -9.5620e-02,  8.7382e-02,  9.0136e-02,\n",
      "         -8.6817e-02,  5.1294e-02, -2.8576e-02, -6.9883e-02,  3.5618e-02,\n",
      "         -3.4595e-03,  6.4491e-03,  6.5968e-02,  4.1101e-02, -2.6776e-04,\n",
      "         -9.9743e-02,  6.5878e-02,  5.7056e-02, -5.7839e-02,  4.1750e-02,\n",
      "         -6.1735e-02,  5.9395e-03,  6.8143e-03, -4.7855e-02, -7.9173e-02,\n",
      "          4.2089e-02, -4.3147e-02, -7.3881e-02,  5.0338e-02, -6.7314e-02,\n",
      "         -8.8525e-02, -9.0019e-02, -7.8749e-02,  3.7295e-02,  3.6759e-02,\n",
      "          2.2325e-03,  4.6223e-03,  5.5768e-04, -9.3287e-02,  4.2151e-02,\n",
      "         -4.0960e-02,  9.1319e-02, -1.3177e-02, -4.8314e-02, -3.2168e-02,\n",
      "          2.9328e-02,  3.9271e-02, -1.0309e-01, -8.7041e-02],\n",
      "        [-1.0909e-01, -4.7391e-02, -9.3217e-02, -2.0042e-02, -8.3022e-02,\n",
      "         -7.6537e-02,  4.3620e-02, -5.4289e-02,  1.5617e-02, -1.0671e-01,\n",
      "         -7.7736e-02, -4.4433e-02, -1.8287e-02,  5.3246e-02, -2.0918e-02,\n",
      "          1.6057e-02,  3.1772e-02, -4.9284e-02,  1.2324e-02, -1.6249e-02,\n",
      "         -6.3867e-02,  3.7830e-02, -1.0783e-01, -7.4728e-02,  7.8156e-02,\n",
      "          6.5337e-02,  7.2698e-02, -1.0768e-01, -1.0749e-01, -1.0508e-01,\n",
      "          4.5427e-02, -4.1994e-02, -5.3859e-03,  1.0185e-01, -1.0620e-01,\n",
      "          3.4929e-02, -1.0630e-01,  3.7693e-02, -3.4943e-02,  9.3607e-02,\n",
      "         -6.0101e-02, -1.3997e-02, -2.1942e-02, -1.0883e-01,  5.3068e-03,\n",
      "         -9.5871e-02,  2.8151e-02, -3.9923e-02,  1.3378e-02,  9.9014e-02,\n",
      "         -4.2209e-02, -7.3116e-02,  5.6174e-02, -6.1859e-02, -1.1401e-02,\n",
      "          1.0899e-01, -1.0362e-01, -3.2747e-02, -4.2730e-02,  6.1456e-02,\n",
      "          3.3909e-02,  7.4059e-02,  8.9063e-02, -8.7445e-03, -2.6373e-02,\n",
      "          2.9640e-02, -9.8699e-02,  2.3425e-02, -9.2624e-02,  9.4165e-03,\n",
      "         -9.0704e-02,  9.5582e-02, -3.4126e-02,  7.0581e-02, -7.7431e-02,\n",
      "         -2.6525e-02, -7.7455e-02, -8.6203e-03, -3.4135e-03,  1.0734e-01,\n",
      "         -1.9765e-02,  1.1737e-02,  3.3624e-02, -7.9064e-02],\n",
      "        [-7.9825e-02, -3.0029e-02,  7.9353e-02, -2.3281e-02,  8.0898e-02,\n",
      "          1.0592e-01, -7.4029e-02,  5.0739e-02,  1.5551e-02, -2.3485e-02,\n",
      "          1.7727e-02, -3.7860e-02, -9.6028e-02,  9.4797e-02, -7.6812e-02,\n",
      "         -4.2107e-02, -1.0222e-01, -2.9359e-02,  7.3032e-02,  4.3034e-03,\n",
      "          9.4302e-02, -1.9002e-02,  5.3995e-02, -3.8431e-02, -5.7634e-02,\n",
      "          9.2453e-02,  3.6769e-02, -1.6206e-02,  5.6525e-03, -4.7463e-02,\n",
      "         -5.9195e-02,  2.1824e-02,  7.1649e-02, -2.9012e-03, -9.3979e-02,\n",
      "          6.6419e-02,  8.0123e-02, -5.4782e-02,  2.6409e-02, -4.0459e-02,\n",
      "          3.8351e-02, -3.6175e-02, -4.7269e-02,  5.2651e-02, -1.0055e-01,\n",
      "          2.1943e-02, -7.2265e-02, -9.6648e-02,  1.9218e-02, -7.6447e-02,\n",
      "         -7.2138e-02,  3.5504e-02, -1.1579e-03, -3.7113e-02,  3.1377e-02,\n",
      "          7.0794e-02,  1.9153e-02,  8.3755e-02,  3.5041e-02, -6.5803e-03,\n",
      "          1.0437e-01, -7.1509e-02, -4.8027e-02,  2.0298e-03, -6.1129e-02,\n",
      "         -3.3663e-02,  8.0072e-02, -6.0442e-02, -6.0633e-02, -1.0197e-01,\n",
      "          6.4625e-02,  1.9817e-02, -6.5336e-04, -2.7748e-02, -1.0534e-01,\n",
      "          5.3719e-02,  7.4975e-02, -8.6616e-02,  1.1687e-03, -9.1703e-02,\n",
      "         -1.2978e-02,  2.9315e-02,  7.1631e-02, -5.1494e-02],\n",
      "        [ 6.0639e-02, -9.6291e-02,  4.7192e-02,  8.8043e-02, -8.3618e-02,\n",
      "         -6.5510e-02,  1.8747e-02,  6.1485e-03,  1.0138e-01, -3.8088e-02,\n",
      "          1.0009e-01,  6.3716e-03, -8.3553e-02,  6.2293e-02,  6.5545e-02,\n",
      "          4.3594e-02, -9.5472e-02, -1.0341e-01,  6.7705e-02,  6.0810e-02,\n",
      "          5.5077e-02,  6.2856e-02, -7.5667e-02, -9.5023e-02,  3.7358e-02,\n",
      "         -8.9148e-02, -2.5246e-02, -5.0724e-02,  3.1078e-02,  8.3933e-02,\n",
      "         -4.0361e-02, -9.9833e-02,  1.9147e-02,  9.5910e-03,  9.1119e-02,\n",
      "         -5.3540e-02,  7.3728e-02, -9.7897e-02,  1.6192e-02, -1.6319e-03,\n",
      "         -3.9496e-02, -8.7115e-02,  1.0221e-01, -4.3496e-02, -7.3145e-02,\n",
      "          8.0885e-03, -7.8254e-02, -5.1016e-02, -3.9553e-02,  7.4426e-02,\n",
      "          7.6533e-03,  3.4024e-02, -7.8887e-02,  9.2870e-02,  5.6307e-02,\n",
      "         -4.7205e-02,  5.7720e-02, -8.4367e-02, -1.4185e-02,  6.8628e-02,\n",
      "         -1.0239e-01,  2.4911e-02,  3.9217e-03,  8.4107e-03, -4.1874e-02,\n",
      "         -1.0125e-01, -1.5036e-02,  5.3552e-02, -3.2992e-02,  2.3056e-02,\n",
      "         -3.1877e-02,  3.5748e-02,  3.4892e-02,  3.2266e-02, -9.9230e-02,\n",
      "          9.2844e-02,  5.9520e-02, -9.9644e-02,  1.3212e-02,  2.8910e-02,\n",
      "          3.2010e-02, -7.8111e-02, -7.9206e-02,  7.3830e-02]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0030, -0.0565,  0.0174,  0.0270,  0.0049,  0.0022, -0.0559,  0.0778,\n",
      "         0.0384, -0.0738], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let try a random 32x32 input. Note: expected input size of this net (LeNet) is 32x32. To use this net on MNIST dataset, please resize the images from the dataset to 32x32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0585, -0.0562,  0.0417,  0.0154, -0.0008,  0.0437, -0.1086,  0.0539,\n",
      "          0.0215, -0.0857]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn((1, 1, 32, 32))\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero the gradient buffers of all parameters and backprops with random gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Note\n",
    "   \n",
    "   *torch.nn* only supports mini-batches. The entire *torch.nn* package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
    "\n",
    "   For example, *nn.Conv2d* will take in a 4D Tensor of *nSamples x nChannels x Height x Width*.\n",
    "\n",
    "   If you have a single sample, just use *input.unsqueeze(0)* to add a fake batch dimension.\n",
    "   \n",
    "Before proceeding further, let’s recap all the classes you’ve seen so far.\n",
    "\n",
    "### Recap:\n",
    "\n",
    "* **torch.Tensor** - A multi-dimensional array with support for autograd operations like *backward()*. Also holds the gradient w.r.t. the tensor.\n",
    "* **nn.Module** - Neural network module. Convenient way of encapsulating parameters, with helpers for moving them to GPU, exporting, loading, etc.\n",
    "* **nn.Parameter** - A kind of Tensor, that is automatically registered as a parameter when assigned as an attribute to a *Module*.\n",
    "* **autograd.Function** - Implements *forward* and *backward* definitions of an autograd operation. Every *Tensor* operation creates at least a single *Function* node that connects to functions that created a Tensor and encodes its history.\n",
    "\n",
    "### At this point, we covered:\n",
    "\n",
    "* Defining a neural network\n",
    "\n",
    "* Processing inputs and calling backward\n",
    "\n",
    "### Still Left:\n",
    "\n",
    "* Computing the loss\n",
    "* Updating the weights of the network\n",
    "\n",
    "# Loss Function\n",
    "\n",
    "A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target.\n",
    "\n",
    "There are several different loss functions under the nn package . A simple loss is: *nn.MSELoss* which computes the mean-squared error between the input and the target.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8338, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)\n",
    "target = target.view((1, -1))\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you follow *loss* in the backward direction, using its *.grad_fn* attribute, you will see a graph of computations that looks like this:\n",
    "\n",
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> view -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss\n",
    "      \n",
    "So, when we call *loss.backward()*, the whole graph is differentiated w.r.t. the loss, and all Tensors in the graph that has *equires_grad=True* will have their *.grad* Tensor accumulated with the gradient.\n",
    "\n",
    "For illustration, let us follow a few steps backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x7f3a50895dd8>\n",
      "<AddmmBackward object at 0x7f3a50895e10>\n",
      "<AccumulateGrad object at 0x7f3a50895dd8>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn) # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backprop\n",
    "\n",
    "To backpropagate the error all we have to do is to *loss.backward()*. You need to clear the existing gradients though, else gradients will be accumulated to existing gradients.\n",
    "\n",
    "Now we shall call *loss.backward()*, and have a look at conv1’s bias gradients before and after the backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0210, -0.0065, -0.0001,  0.0362, -0.0197, -0.0054])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have seen how to use loss functions.\n",
    "\n",
    "* Read Later:\n",
    "\n",
    "    The neural network package contains various modules and loss functions that form the building blocks of deep neural networks. A full list with documentation is [here](https://pytorch.org/docs/nn).\n",
    "    \n",
    "### The only thing left to learn is:\n",
    "\n",
    "* Updating the weights of the network\n",
    "\n",
    "# Update the weights\n",
    "\n",
    "The simplest update rule used in practice is the Stochastic Gradient Descent (SGD):\n",
    "\n",
    "*weight = weight - learning_rate * gradient*\n",
    "\n",
    "We can implement this using simple python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as you use neural networks, you want to use various different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc. To enable this, we built a small package: *torch.optim* that implements all these methods. Using it is very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "# in your training loop\n",
    "optimizer.zero_grad() # zero\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note\n",
    "   \n",
    "   Observe how gradient buffers had to be manually set to zero using optimizer.zero_grad(). This is because gradients are accumulated as explained in Backprop section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
